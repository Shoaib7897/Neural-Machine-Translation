{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rZ0PDjk0Le5G"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split                        \n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bx3KLIb2ywAF",
    "outputId": "55eb9292-0978-41f0-aaa0-7b21ce836ecc"
   },
   "outputs": [],
   "source": [
    "path_to_zip=tf.keras.utils.get_file(\"spa-eng.zip\",origin=\"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",extract=True)\n",
    "path_to_file=os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Du62queS0oCh"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US1zHcvizCqs",
    "outputId": "82e4f1ee-6e59-466a-811c-2c34ea8755e1"
   },
   "outputs": [],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mpMEMcLfmi1"
   },
   "outputs": [],
   "source": [
    "def create_dataset(path,num_examples):\n",
    "  lines=io.open(path,encoding='UTF-8').read().strip().split('\\n')\n",
    "  word_pairs=[[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmugoaM7gn47",
    "outputId": "c6e4fc53-3e09-4f4f-8eae-39cbc30e8468"
   },
   "outputs": [],
   "source": [
    "en,sp=create_dataset(path_to_file,None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK5NGgQ5g7RU"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer=tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "  tensor=lang_tokenizer.texts_to_sequences(lang)\n",
    "  tensor=tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "  return tensor,lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbyqtQ0Akv9x"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path,num_examples=None):\n",
    "  targ_lang,inp_lang=create_dataset(path,num_examples)\n",
    "  input_tensor,inp_lang_tokenizer=tokenize(inp_lang)\n",
    "  target_tensor,targ_lang_tokenizer=tokenize(targ_lang)\n",
    "  return input_tensor,target_tensor,inp_lang_tokenizer,targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lJboVBEl8hK"
   },
   "outputs": [],
   "source": [
    "num_examples=30000\n",
    "input_tensor,target_tensor,inp_lang,targ_lang=load_dataset(path_to_file,num_examples)\n",
    "max_length_targ,max_length_inp=target_tensor.shape[1],input_tensor.shape[1]\n",
    "input_tensor_train,input_tensor_val,target_tensor_train,target_tensor_val=train_test_split(input_tensor,target_tensor, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_6wJf3pn0O_"
   },
   "outputs": [],
   "source": [
    "def convert(lang,tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print(\"%d---->%s\"%(t,lang.index_word[t]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bX20uMSksE3R",
    "outputId": "1e26756d-e277-4761-c656-f0bbb99bf212"
   },
   "outputs": [],
   "source": [
    "print(\"input languauge; index to word mapping\")\n",
    "convert(inp_lang,input_tensor_train[0])\n",
    "print(\"target languauge; index to word mapping\")\n",
    "convert(targ_lang,target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlwL8V4-tXUt",
    "outputId": "b7ddb90f-c863-4760-e631-4cd9f9d5918c"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE=len(input_tensor_train)\n",
    "BATCH_SIZE=64\n",
    "steps_per_epoch=len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim=256\n",
    "units=1024\n",
    "vocab_inp_size=len(inp_lang.word_index)+1\n",
    "vocab_targ_size=len(targ_lang.word_index)+1\n",
    "dataset=tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset=dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "example_input_batch,example_target_batch=next(iter(dataset))\n",
    "example_input_batch.shape,example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3vX8lhkw0Dk"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocj6OtPdXbKO",
    "outputId": "f17e9548-0636-49f7-bc87-7c8cb2d85ebd"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfc4ZdgiYu4-"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzduDqhlcG4O"
   },
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvkKHryncjgW"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    x = self.embedding(x)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "    output, state = self.gru(x)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    x = self.fc(output)\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qs--s05yfpw3",
    "outputId": "1b9ca164-7bc7-419c-a087-3dcb9801e881"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_targ_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUmTUkVEgs1A"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkWnnTCvigVW"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder,decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHAUuvLujQJc"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOyhfe-No5C0",
    "outputId": "7586e5ab-d492-44de-8895-b965e6d35fa8"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch,batch_loss.numpy()))\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uhnzjqdrocO"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "  result = ''\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB7P3JfIDajT"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention,sentence,predicted_sentence):\n",
    "  fig=plt.figure(figsize=(10,10))\n",
    "  ax=fig.add_subplot(1,1,1)\n",
    "  ax.matshow(attention,cmap='viridis')\n",
    "  fontdict = {'fontsize': 14}\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCZ2gsPOEisE"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result,sentence,attention_plot=evaluate(sentence)\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "  attention_plot=attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot,sentence.split(' '),result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFCXoMThGImY",
    "outputId": "00ac868b-7cf5-4afc-daf7-746e3a2d1fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd159906590>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "GDndwvo3GTSe",
    "outputId": "7aa0c375-f037-4849-9512-617065878d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> tengo un carro <end>\n",
      "Predicted translation: i have a car . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'tengo un carro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2wK8K_Hz7lD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDYflZ3GGqDP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Machine Translation ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
